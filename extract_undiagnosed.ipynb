{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e880bf-a897-4f77-80f5-cec285cf1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from DataFields import DataFields, DropNAList, DateReportedFields\n",
    "from ProjectFunctions import get_columns_from_chunk, convert_date_to_binary, drop_rows_with_na_greater_than\n",
    "from ProjectFunctions import map_education_levels, map_vascular_levels\n",
    "from typing import Callable, Any\n",
    "\n",
    "UKBB_PATH = \"~/biobank/ukb672220.csv\"\n",
    "\n",
    "VD_COL = \"Vascular Dementia Report Date\"\n",
    "\n",
    "# A dictionary containing the used features\n",
    "datafields = DataFields\n",
    "\n",
    "# Features of conditions specified by date\n",
    "datereportedfields = DateReportedFields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e49da3-8794-487a-a16d-f8c901dfa2b7",
   "metadata": {},
   "source": [
    "#### Measure the distribution of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a730a70-d42e-41ea-8b6e-42ddf207f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diagnosed_processed.csv\")\n",
    "\n",
    "# plot histogram of the birth year\n",
    "df[\"Birth Year\"].plot(kind='hist', bins=10, edgecolor='black')\n",
    "birth_year_counts_histogram, birth_year_histogram_edges = np.histogram(df[\"Birth Year\"], bins=10)\n",
    "birth_year_histogram_edges = np.floor(birth_year_histogram_edges).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4462b4-4ef6-4214-824c-e857d8929294",
   "metadata": {},
   "source": [
    "#### Extract samples of patients undiagnosed with vascular dementia with similar birth year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d803e75-a256-461d-b16a-565973c72d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Define features to drop if na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b447d9-1529-48ba-9310-d93cb43a1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_if_na_list = [\n",
    "    \"Birth Year\",\n",
    "    \"Sex\",\n",
    "    \"Education\",\n",
    "    \"Smoking Status\",\n",
    "    \"Ever Smoked\",\n",
    "    \"Alcohol Intake Frequency\",\n",
    "    \"Diabetes Diagnosed By Doctor\",\n",
    "    \"Report of vascular problems\",\n",
    "    \n",
    "# Blood Chem\n",
    "    \"Alanine aminotransferase\",\n",
    "    \"Albumin\",\n",
    "    \"Alkaline phosphatase\",\n",
    "    \"Apolipoprotein A\",\n",
    "    \"Apolipoprotein B\",\n",
    "    \"Aspartate aminotransferase\",\n",
    "    \"C-reactive protein\",\n",
    "    \"Calcium\",\n",
    "    \"Cholesterol\",\n",
    "    \"Creatinine\",\n",
    "    \"Cystatin C\",\n",
    "    \"Direct bilirubin\",\n",
    "    \"Gamma glutamyltransferase\",\n",
    "    \"Glucose\",\n",
    "    \"Glycated haemoglobin (HbA1c)\",\n",
    "    \"HDL cholesterol\",\n",
    "    \"IGF-1\",\n",
    "    \"LDL direct\",\n",
    "    \"Lipoprotein A\",\n",
    "    \"Phosphate\",\n",
    "    \"SHBG\",\n",
    "    \"Testosterone\",\n",
    "    \"Total bilirubin\",\n",
    "    \"Total protein\",\n",
    "    \"Triglycerides\",\n",
    "    \"Urate\",\n",
    "    \"Urea\",\n",
    "    \"Vitamin D\",\n",
    "    \n",
    "# Blood Count\n",
    "    \"Basophil count\",\n",
    "    \"Basophil percentage\",\n",
    "    \"Eosinophil count\",\n",
    "    \"Eosinophil percentage\",\n",
    "    \"Haematocrit percentage\",\n",
    "    \"Haemoglobin concentration\",\n",
    "    \"High light scatter reticulocyte count\",\n",
    "    \"High light scatter reticulocyte percentage\",\n",
    "    \"Immature reticulocyte fraction\",\n",
    "    \"Lymphocyte count\",\n",
    "    \"Lymphocyte percentage\",\n",
    "    \"Mean corpuscular haemoglobin\",\n",
    "    \"Mean corpuscular haemoglobin concentration\",\n",
    "    \"Mean corpuscular volume\",\n",
    "    \"Mean platelet (thrombocyte) volume\",\n",
    "    \"Mean reticulocyte volume\",\n",
    "    \"Mean sphered cell volume\",\n",
    "    \"Monocyte count\",\n",
    "    \"Monocyte percentage\",\n",
    "    \"Neutrophil count\",\n",
    "    \"Neutrophil percentage\",\n",
    "    \"Nucleated red blood cell count\",\n",
    "    \"Nucleated red blood cell percentage\",\n",
    "    \"Platelet count\",\n",
    "    \"Platelet crit\",\n",
    "    \"Platelet distribution width\",\n",
    "    \"Red blood cell (erythrocyte) count\",\n",
    "    \"Red blood cell (erythrocyte) distribution width\",\n",
    "    \"Reticulocyte count\",\n",
    "    \"Reticulocyte percentage\",\n",
    "    \"White blood cell (leukocyte) count\",\n",
    "\n",
    "# Blood Presure\n",
    "    \"Blood Pressure Diastolic\",\n",
    "    \"Blood Pressure Systolic\",\n",
    "    \"Pulse Rate at Blood Pressure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a85fc-28a9-432d-bf7d-e1923817369e",
   "metadata": {},
   "source": [
    "##### Do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1619ec4-b181-487a-9765-aafe8caff2c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_chunk(chunk, column, condition):\n",
    "    # remove unnecessary columns first.\n",
    "    chunk = get_columns_from_chunk(chunk, datafields, oldest=True)\n",
    "\n",
    "    chunk = map_education_levels(chunk)\n",
    "    \n",
    "    chunk[\"Report of vascular problems\"] = chunk[\"Report of vascular problems\"].replace({-7: 0, -3: pd.NA})\n",
    "\n",
    "    # take only patients undiagnosed with vascular dementia\n",
    "    chunk = chunk[chunk[VD_COL].isna()]\n",
    "    \n",
    "    # filter by condition function\n",
    "    mask = condition(chunk[column])\n",
    "    filtered_chunk = chunk.loc[mask]\n",
    "    \n",
    "    # convert items with value less than 0 to NA\n",
    "    filtered_chunk = filtered_chunk.mask(filtered_chunk.select_dtypes(include='number') < 0)\n",
    "    \n",
    "    # drop all NA\n",
    "    #filtered_chunk = filtered_chunk.dropna(subset=DropNAList) # drop if missing value for some columns\n",
    "    filtered_chunk = drop_rows_with_na_greater_than(filtered_chunk, x=40, include=DropNAList)\n",
    "    \n",
    "    return filtered_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e3b87-c676-4a41-aaf3-327f79877ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample \"count\" rows from dataframe following a condtion by chunks randomly.\n",
    "def sample_by_condition(file_path, column, condition, count, samples_per_chunk, chunksize=10000):\n",
    "    result = pd.DataFrame()\n",
    "    samples_collected = 0\n",
    "    \n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):\n",
    "            \n",
    "        filtered_chunk = filter_chunk(chunk, column, condition)\n",
    "        \n",
    "        if filtered_chunk.empty:\n",
    "            continue\n",
    "        \n",
    "        remaining_samples = count - samples_collected\n",
    "        if remaining_samples <= 0:\n",
    "            break\n",
    "            \n",
    "        # choose randomly if too many were collected\n",
    "        k = min(samples_per_chunk, len(filtered_chunk))\n",
    "        chunk_sample = filtered_chunk.sample(n=k)\n",
    "    \n",
    "        if result.empty:\n",
    "            result = chunk_sample\n",
    "        else:\n",
    "            result = pd.concat([result, chunk_sample], ignore_index=True, copy=False)\n",
    "\n",
    "        samples_collected += len(chunk_sample)\n",
    "\n",
    "        if samples_collected >= count:\n",
    "            break\n",
    "            \n",
    "    if samples_collected > count:\n",
    "        return result.sample(n=count)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78765fb3-7fdc-41b6-a2da-b9ff4bd73f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_chunk = 100 # maximum samples to take from a single chunk per histogram column\n",
    "col_name = \"Birth Year\" # The column to use as a rule for \"sample_by_condition\"\n",
    "\n",
    "const = 20 # constant addition per histogram\n",
    "\n",
    "undiagnosed_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(birth_year_counts_histogram)):\n",
    "    start, end = int(birth_year_histogram_edges[i]), int(birth_year_histogram_edges[i+1])\n",
    "    count = birth_year_counts_histogram[i]\n",
    "    \n",
    "    df = sample_by_condition(UKBB_PATH,\n",
    "                             col_name,\n",
    "                             lambda x:(x >= start) & (x < end),\n",
    "                             count + const,\n",
    "                             per_chunk,\n",
    "                            )\n",
    "    print(f\"{i+1} / {len(birth_year_counts_histogram)}: range {start} - {end}, gathered {len(df)}/{count+const}\")\n",
    "    \n",
    "    undiagnosed_df = pd.concat([undiagnosed_df, df], ignore_index=True)\n",
    "\n",
    "# assign undiagnosed\n",
    "#undiagnosed_df[\"Vascular Dementia Report Date\"] = pd.NA\n",
    "\n",
    "# drop id column\n",
    "undiagnosed_df = undiagnosed_df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f6d77-248b-441b-b20e-b43640e382cd",
   "metadata": {},
   "source": [
    "#### Save the CSV, and analyse the extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c178ec1-9dea-4812-8ce5-8229f3f407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProjectFunctions import count_na_in_dataframe\n",
    "\n",
    "# count number of NA per column\n",
    "count_na_in_dataframe(undiagnosed_df)\n",
    "\n",
    "# Plot Brith Year histogram, compare with diagnosed patients\n",
    "undiagnosed_df[\"Birth Year\"].plot(kind='hist', bins=10, edgecolor='black')\n",
    "\n",
    "undiagnosed_df.to_csv(\"undiagnosed.csv\", index=False)\n",
    "\n",
    "# analyze distributions\n",
    "undiagnosed_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
